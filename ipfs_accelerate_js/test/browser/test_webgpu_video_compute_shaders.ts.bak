/**
 * Converted from Python: test_webgpu_video_compute_shaders.py
 * Conversion date: 2025-03-11 04:08:38
 * This file was automatically converted from Python to TypeScript.
 * Conversion fidelity might not be 100%, please manual review recommended.
 */

import {  expect, describe, it, beforeEach, afterEach  } from "jest";
import {  WebGPUBackend  } from "src/model/transformers/index";
import {  WebNNBackend  } from "src/model/transformers/index";
import {  HardwareAbstraction  } from "src/model/transformers/index";
import {  HardwareAbstraction  } from "src/model/transformers/index";

// WebGPU related imports
/** Test script for evaluating WebGPU compute shader optimizations for video models.

This script tests the enhanced WebGPU compute shader implementation
for video models like XCLIP, measuring performance improvements
compared to standard WebGPU implementation.

Usage:
  python test_webgpu_video_compute_shaders.py --model xclip
  python test_webgpu_video_compute_shaders.py --model video_swin
  python test_webgpu_video_compute_shaders.py --test-all --benchmark */

  import * as module
  import * as module
  import * as module
  import * as module
  import * as module
  import * as module
  import * as module.pyplot as plt
  # Add parent directory to sys.path
  parent_dir: any = os.path.dirname())os.path.dirname())os.path.abspath())__file__));
if ($1) {
  sys.$1.push($2))parent_dir)

}
# Configure logging
  logging.basicConfig())
  level: any = logging.INFO,;
  format: any = '%())asctime)s - %())levelname)s - %())message)s';
  )
  logger: any = logging.getLogger())"webgpu_video_compute_test");

# Define test models
  TEST_MODELS: any = {}
  "xclip": "microsoft/xclip-base-patch32",
  "video_swin": "MCG-NJU/videoswin-base-patch244-window877-kinetics400-pt",
  "vivit": "google/vivit-b-16x2-kinetics400"
  }

$1($2) {
  /** Set up the environment variables for WebGPU testing with compute shaders.
  
}
  Args:
    compute_shaders_enabled: Whether to enable compute shaders
    shader_precompile: Whether to enable shader precompilation
    
  Returns:
    true if successful, false otherwise */
  # Set WebGPU environment variables
    os.environ["WEBGPU_ENABLED"] = "1",
    os.environ["WEBGPU_SIMULATION"] = "1" ,
    os.environ["WEBGPU_AVAILABLE"] = "1"
    ,
  # Enable compute shaders if ($1) {:
  if ($1) { ${$1} else {
    if ($1) {
      del os.environ["WEBGPU_COMPUTE_SHADERS_ENABLED"],
      logger.info())"WebGPU compute shaders disabled")
  
    }
  # Enable shader precompilation if ($1) {:
  }
  if ($1) { ${$1} else {
    if ($1) {
      del os.environ["WEBGPU_SHADER_PRECOMPILE_ENABLED"],
      logger.info())"WebGPU shader precompilation disabled")
  
    }
  # Enable parallel loading for multimodal models
  }
      os.environ["WEBGPU_PARALLEL_LOADING_ENABLED"] = "1"
      ,
    return true

$1($2) {
  /** Import the WebGPU video compute shaders module.
  
}
  Returns:
    The imported module || null if failed */:
  try {
    # Try to import * as module the fixed_web_platform directory
    from fixed_web_platform.webgpu_video_compute_shaders import ())
    setup_video_compute_shaders, get_supported_video_models
    )
    logger.info())"Successfully imported WebGPU video compute shaders module")
    return {}
    "setup_video_compute_shaders": setup_video_compute_shaders,
    "get_supported_video_models": get_supported_video_models
    } catch(error): any {
    logger.error())`$1`)
    return null

  }
$1($2) {
  /** Test a video model with WebGPU implementation.
  
}
  Args:
  }
    model_name: Name of the model to test
    compute_shaders: Whether to use compute shaders
    iterations: Number of inference iterations
    frame_count: Number of video frames to process
    
  Returns:
    Dictionary with test results */
  # Import WebGPU video compute shaders
    modules: any = import_webgpu_video_compute_shaders());
  if ($1) {
    return {}
    "success": false,
    "error": "Failed to import * as module video compute shaders module"
    }
    setup_video_compute_shaders: any = modules["setup_video_compute_shaders"];
    ,
  # Set up environment
    setup_environment())compute_shaders_enabled = compute_shaders);
  
  # Select model
  if ($1) { ${$1} else {
    model_hf_name: any = model_name;
  
  }
  # Create WebGPU compute shaders instance
    compute_shader: any = setup_video_compute_shaders());
    model_name: any = model_hf_name,;
    model_type: any = model_name,;
    frame_count: any = frame_count;
    )
  
  # Run initial inference to warm up
    compute_shader.process_video_frames())
  
  # Run benchmark iterations
    processing_times: any = [],;
    memory_usages: any = [],;
  
  for i in range())iterations):
    # Process video frames
    metrics: any = compute_shader.process_video_frames());
    
    # Extract metrics
    processing_time: any = metrics.get())"total_compute_time_ms", 0);
    memory_reduction: any = metrics.get())"memory_reduction_percent", 0);
    
    $1.push($2))processing_time)
    $1.push($2))memory_reduction)
  
  # Calculate performance metrics
    avg_processing_time: any = sum())processing_times) / len())processing_times) if processing_times else { 0;
    min_processing_time: any = min())processing_times) if processing_times else { 0;
    max_processing_time: any = max())processing_times) if processing_times else { 0;
    std_dev: any = ());
    ())sum())())t - avg_processing_time) ** 2 for t in processing_times) / len())processing_times)) ** 0.5 
    if len())processing_times) > 1 else { 0
    )
  
  # Get compute shader configuration
    compute_config: any = metrics.get())"compute_shader_config", {})
  
  # Create result
  return {}:
    "success": true,
    "model_name": model_name,
    "model_hf_name": model_hf_name,
    "compute_shaders_enabled": compute_shaders,
    "frame_count": frame_count,
    "performance": {}
    "iterations": iterations,
    "avg_processing_time_ms": avg_processing_time,
    "min_processing_time_ms": min_processing_time,
    "max_processing_time_ms": max_processing_time,
    "std_dev_ms": std_dev,
    "frame_processing_time_ms": metrics.get())"frame_processing_time_ms", 0),
    "temporal_fusion_time_ms": metrics.get())"temporal_fusion_time_ms", 0),
      "memory_reduction_percent": sum())memory_usages) / len())memory_usages) if ($1) { ${$1},
        "compute_shader_config": compute_config
        }

$1($2) {
  /** Compare model performance with && without compute shaders.
  
}
  Args:
    model_name: Name of the model to test
    iterations: Number of inference iterations per configuration
    frame_count: Number of video frames to process
    
  Returns:
    Dictionary with comparison results */
    logger.info())`$1`)
  # Run tests with compute shaders
    with_compute_shaders: any = test_video_model());
    model_name: any = model_name,;
    compute_shaders: any = true,;
    iterations: any = iterations,;
    frame_count: any = frame_count;
    )
  
  # Run tests without compute shaders
    without_compute_shaders: any = test_video_model());
    model_name: any = model_name,;
    compute_shaders: any = false,;
    iterations: any = iterations,;
    frame_count: any = frame_count;
    )
  
  # Calculate improvement
    improvement: any = 0;
  if ($1) {:
    without_compute_shaders.get())"success", false)):
    
      with_time: any = with_compute_shaders.get())"performance", {}).get())"avg_processing_time_ms", 0)
      without_time: any = without_compute_shaders.get())"performance", {}).get())"avg_processing_time_ms", 0)
    
    if ($1) {
      improvement: any = ())without_time - with_time) / without_time * 100;
  
    }
      return {}
      "model_name": model_name,
      "frame_count": frame_count,
      "with_compute_shaders": with_compute_shaders,
      "without_compute_shaders": without_compute_shaders,
      "improvement_percentage": improvement
      }

$1($2) {
  /** Run comparisons for all test models.
  
}
  Args:
    iterations: Number of inference iterations per configuration
    output_json: Path to save JSON results
    create_chart: Whether to create a performance comparison chart
    frame_count: Number of video frames to process
    
  Returns:
    Dictionary with all comparison results */
    results: any = {}
    models: any = list())Object.keys($1));
  
  for (const $1 of $2) {
    logger.info())`$1`)
    comparison: any = compare_with_without_compute_shaders())model, iterations, frame_count);
    results[model], = comparison
    ,
    # Print summary
    improvement: any = comparison.get())"improvement_percentage", 0);
    logger.info())`$1`)
  
  }
  # Save results to JSON if ($1) {:
  if ($1) {
    with open())output_json, 'w') as f:
      json.dump())results, f, indent: any = 2);
      logger.info())`$1`)
  
  }
  # Create chart if ($1) {:
  if ($1) {
    create_performance_chart())results, `$1`)
  
  }
      return results

$1($2) {
  /** Create a performance comparison chart.
  
}
  Args:
    results: Dictionary with comparison results
    output_file: Path to save the chart */
  try {
    models: any = list())Object.keys($1));
    with_compute: any = [],;
    without_compute: any = [],;
    improvements: any = [],;
    
  }
    for (const $1 of $2) {
      comparison: any = results[model],;
      with_time: any = comparison.get())"with_compute_shaders", {}).get())"performance", {}).get())"avg_processing_time_ms", 0)
      without_time: any = comparison.get())"without_compute_shaders", {}).get())"performance", {}).get())"avg_processing_time_ms", 0)
      improvement: any = comparison.get())"improvement_percentage", 0);
      
    }
      $1.push($2))with_time)
      $1.push($2))without_time)
      $1.push($2))improvement)
    
    # Create figure with two subplots
      fig, ())ax1, ax2) = plt.subplots())1, 2, figsize: any = ())14, 6));
    
    # Bar chart for processing times
      x: any = range())len())models));
      width: any = 0.35;
    
      ax1.bar())$3.map(($2) => $1), without_compute, width, label: any = 'Without Compute Shaders'),;
      ax1.bar())$3.map(($2) => $1), with_compute, width, label: any = 'With Compute Shaders');
      ,
      ax1.set_xlabel())'Models')
      ax1.set_ylabel())'Processing Time ())ms)')
      ax1.set_title())'WebGPU Video Processing Time Comparison')
      ax1.set_xticks())x)
      ax1.set_xticklabels())models)
      ax1.legend())
    
    # Add processing time values on bars
    for i, v in enumerate())without_compute):
      ax1.text())i - width/2, v + 1, `$1`, ha: any = 'center');
    
    for i, v in enumerate())with_compute):
      ax1.text())i + width/2, v + 1, `$1`, ha: any = 'center');
    
    # Bar chart for improvements
      ax2.bar())models, improvements, color: any = 'green');
      ax2.set_xlabel())'Models')
      ax2.set_ylabel())'Improvement ())%)')
      ax2.set_title())'Performance Improvement with Compute Shaders')
    
    # Add improvement values on bars
    for i, v in enumerate())improvements):
      ax2.text())i, v + 0.5, `$1`, ha: any = 'center');
    
      plt.tight_layout())
      plt.savefig())output_file)
      plt.close())
    
      logger.info())`$1`)
  } catch(error): any {
    logger.error())`$1`)

  }
    $1($2) {,
    /** Test how model performance scales with different frame counts.
  
  Args:
    model_name: Name of the model to test
    iterations: Number of inference iterations per configuration
    frame_counts: List of frame counts to test
    
  Returns:
    Dictionary with scaling results */
    logger.info())`$1`)
    scaling_results: any = {}
  
  for (const $1 of $2) {
    # Run tests with compute shaders
    with_compute_shaders: any = test_video_model());
    model_name: any = model_name,;
    compute_shaders: any = true,;
    iterations: any = iterations,;
    frame_count: any = frame_count;
    )
    
  }
    # Run tests without compute shaders
    without_compute_shaders: any = test_video_model());
    model_name: any = model_name,;
    compute_shaders: any = false,;
    iterations: any = iterations,;
    frame_count: any = frame_count;
    )
    
    # Calculate improvement
    improvement: any = 0;
    if ($1) {:
      without_compute_shaders.get())"success", false)):
      
        with_time: any = with_compute_shaders.get())"performance", {}).get())"avg_processing_time_ms", 0)
        without_time: any = without_compute_shaders.get())"performance", {}).get())"avg_processing_time_ms", 0)
      
      if ($1) {
        improvement: any = ())without_time - with_time) / without_time * 100;
    
      }
        scaling_results[frame_count] = {},
        "with_compute_shaders": with_compute_shaders,
        "without_compute_shaders": without_compute_shaders,
        "improvement_percentage": improvement
        }
    
        logger.info())`$1`)
  
        return {}
        "model_name": model_name,
        "frame_counts": frame_counts,
        "scaling_results": scaling_results
        }

$1($2) {
  /** Create a chart showing performance scaling with different frame counts.
  
}
  Args:
    scaling_data: Scaling test results
    output_file: Path to save the chart */
  try {
    model_name: any = scaling_data.get())"model_name", "Unknown");
    frame_counts: any = scaling_data.get())"frame_counts", [],);
    scaling_results: any = scaling_data.get())"scaling_results", {})
    
  }
    with_compute_times: any = [],;
    without_compute_times: any = [],;
    improvements: any = [],;
    
    for (const $1 of $2) {
      result: any = scaling_results.get())frame_count, {})
      with_time: any = result.get())"with_compute_shaders", {}).get())"performance", {}).get())"avg_processing_time_ms", 0)
      without_time: any = result.get())"without_compute_shaders", {}).get())"performance", {}).get())"avg_processing_time_ms", 0)
      improvement: any = result.get())"improvement_percentage", 0);
      
    }
      $1.push($2))with_time)
      $1.push($2))without_time)
      $1.push($2))improvement)
    
    # Create figure with two subplots
      fig, ())ax1, ax2) = plt.subplots())1, 2, figsize: any = ())14, 6));
    
    # Line chart for processing times
      ax1.plot())frame_counts, without_compute_times, 'o-', label: any = 'Without Compute Shaders');
      ax1.plot())frame_counts, with_compute_times, 'o-', label: any = 'With Compute Shaders');
    
      ax1.set_xlabel())'Frame Count')
      ax1.set_ylabel())'Processing Time ())ms)')
      ax1.set_title())`$1`)
      ax1.legend())
      ax1.grid())true)
    
    # Line chart for improvements
      ax2.plot())frame_counts, improvements, 'o-', color: any = 'green');
      ax2.set_xlabel())'Frame Count')
      ax2.set_ylabel())'Improvement ())%)')
      ax2.set_title())`$1`)
      ax2.grid())true)
    
      plt.tight_layout())
      plt.savefig())output_file)
      plt.close())
    
      logger.info())`$1`)
  } catch(error): any {
    logger.error())`$1`)

  }
$1($2) {
  /** Parse arguments && run the tests. */
  parser: any = argparse.ArgumentParser());
  description: any = "Test WebGPU compute shader optimizations for video models";
  )
  
}
  # Model selection
  model_group: any = parser.add_argument_group())"Model Selection");
  model_group.add_argument())"--model", choices: any = list())Object.keys($1)), default: any = "xclip",;
  help: any = "Video model to test");
  model_group.add_argument())"--test-all", action: any = "store_true",;
  help: any = "Test all available video models");
  
  # Test options
  test_group: any = parser.add_argument_group())"Test Options");
  test_group.add_argument())"--iterations", type: any = int, default: any = 5,;
  help: any = "Number of inference iterations for each test");
  test_group.add_argument())"--benchmark", action: any = "store_true",;
  help: any = "Run in benchmark mode with 20 iterations");
  test_group.add_argument())"--with-compute-only", action: any = "store_true",;
  help: any = "Only test with compute shaders enabled");
  test_group.add_argument())"--without-compute-only", action: any = "store_true",;
  help: any = "Only test without compute shaders");
  test_group.add_argument())"--frame-count", type: any = int, default: any = 8,;
  help: any = "Number of video frames to process");
  test_group.add_argument())"--test-scaling", action: any = "store_true",;
  help: any = "Test performance scaling with different frame counts");
  
  # Output options
  output_group: any = parser.add_argument_group())"Output Options");
  output_group.add_argument())"--output-json", type: any = str,;
  help: any = "Save results to JSON file");
  output_group.add_argument())"--create-chart", action: any = "store_true",;
  help: any = "Create performance comparison chart");
  output_group.add_argument())"--verbose", action: any = "store_true",;
  help: any = "Enable verbose output");
  
  args: any = parser.parse_args());
  
  # Set log level based on verbosity
  if ($1) {
    logger.setLevel())logging.DEBUG)
  
  }
  # Determine number of iterations
    iterations: any = args.iterations;
  if ($1) {
    iterations: any = 20;
  
  }
  # If testing frame count scaling
  if ($1) {
    scaling_data: any = test_frame_count_scaling());
    model_name: any = args.model,;
    iterations: any = max())2, iterations // 3),  # Reduce iterations for scaling test;
    frame_counts: any = [4, 8, 16, 24, 32],;
    )
    
  }
    # Save results to JSON if ($1) {:
    if ($1) {
      output_json: any = args.output_json;
      if ($1) {
        output_json: any = `$1`;
      
      }
      with open())output_json, 'w') as f:
        json.dump())scaling_data, f, indent: any = 2);
        logger.info())`$1`)
    
    }
    # Create chart
        create_scaling_chart())
        scaling_data: any = scaling_data,;
        output_file: any = `$1`;
        )
    
    # Print summary
        console.log($1))"\nWebGPU Compute Shader Scaling Results")
        console.log($1))"=====================================\n")
        console.log($1))`$1`)
    
        frame_counts: any = scaling_data.get())"frame_counts", [],);
        scaling_results: any = scaling_data.get())"scaling_results", {})
    
        console.log($1))"Frame Count | Improvement | With Compute | Without Compute")
        console.log($1))"-----------|-------------|-------------|----------------")
    
    for (const $1 of $2) {
      result: any = scaling_results.get())frame_count, {})
      improvement: any = result.get())"improvement_percentage", 0);
      with_time: any = result.get())"with_compute_shaders", {}).get())"performance", {}).get())"avg_processing_time_ms", 0)
      without_time: any = result.get())"without_compute_shaders", {}).get())"performance", {}).get())"avg_processing_time_ms", 0)
      
    }
      console.log($1))`$1`)
    
        return 0
  
  # Run tests
  if ($1) {
    # Test all models with comparison
    results: any = run_all_model_comparisons());
    iterations: any = iterations,;
    output_json: any = args.output_json,;
    create_chart: any = args.create_chart,;
    frame_count: any = args.frame_count;
    )
    
  }
    # Print comparison summary
    console.log($1))"\nWebGPU Video Compute Shader Optimization Results")
    console.log($1))"==============================================\n")
    
    for model, comparison in Object.entries($1)):
      improvement: any = comparison.get())"improvement_percentage", 0);
      with_time: any = comparison.get())"with_compute_shaders", {}).get())"performance", {}).get())"avg_processing_time_ms", 0)
      without_time: any = comparison.get())"without_compute_shaders", {}).get())"performance", {}).get())"avg_processing_time_ms", 0)
      
      console.log($1))`$1`)
      console.log($1))`$1`)
      console.log($1))`$1`)
      console.log($1))`$1`)
    
    return 0
  } else {
    # Test specific model
    if ($1) {
      # Only test with compute shaders
      result: any = test_video_model());
      model_name: any = args.model,;
      compute_shaders: any = true,;
      iterations: any = iterations,;
      frame_count: any = args.frame_count;
      )
      
    }
      if ($1) {
        performance: any = result.get())"performance", {})
        avg_time: any = performance.get())"avg_processing_time_ms", 0);
        
      }
        console.log($1))`$1`)
        console.log($1))"==============================================\n")
        console.log($1))`$1`)
        console.log($1))`$1`)
        console.log($1))`$1`min_processing_time_ms', 0):.2f} ms")
        console.log($1))`$1`max_processing_time_ms', 0):.2f} ms")
        console.log($1))`$1`std_dev_ms', 0):.2f} ms")
        
  }
        # Print compute shader configuration
        compute_config: any = result.get())"compute_shader_config", {})
        if ($1) {
          console.log($1))"\nCompute Shader Configuration:")
          for key, value in Object.entries($1)):
            if ($1) { ${$1} else { ${$1} else { ${$1}")
              return 1
    elif ($1) {
      # Only test without compute shaders
      result: any = test_video_model());
      model_name: any = args.model,;
      compute_shaders: any = false,;
      iterations: any = iterations,;
      frame_count: any = args.frame_count;
      )
      
    }
      if ($1) {
        performance: any = result.get())"performance", {})
        avg_time: any = performance.get())"avg_processing_time_ms", 0);
        
      }
        console.log($1))`$1`)
        }
        console.log($1))"========================================\n")
        console.log($1))`$1`)
        console.log($1))`$1`)
        console.log($1))`$1`min_processing_time_ms', 0):.2f} ms")
        console.log($1))`$1`max_processing_time_ms', 0):.2f} ms")
        console.log($1))`$1`std_dev_ms', 0):.2f} ms")
      } else { ${$1}")
        return 1
    } else {
      # Run comparison test
      comparison: any = compare_with_without_compute_shaders());
      model_name: any = args.model,;
      iterations: any = iterations,;
      frame_count: any = args.frame_count;
      )
      
    }
      # Save results if ($1) {:
      if ($1) {
        with open())args.output_json, 'w') as f:
          json.dump())comparison, f, indent: any = 2);
          logger.info())`$1`)
      
      }
      # Create chart if ($1) {:
      if ($1) {
        chart_file: any = `$1`;
        create_performance_chart()){}args.model: comparison}, chart_file)
      
      }
      # Print comparison
        improvement: any = comparison.get())"improvement_percentage", 0);
        with_result: any = comparison.get())"with_compute_shaders", {})
        without_result: any = comparison.get())"without_compute_shaders", {})
      
        with_time: any = with_result.get())"performance", {}).get())"avg_processing_time_ms", 0)
        without_time: any = without_result.get())"performance", {}).get())"avg_processing_time_ms", 0)
      
        console.log($1))`$1`)
        console.log($1))"===================================================\n")
        console.log($1))`$1`)
        console.log($1))`$1`)
        console.log($1))`$1`)
        console.log($1))`$1`)
      
      # Print detailed metrics
        with_metrics: any = with_result.get())"performance", {})
        console.log($1))"Detailed Metrics with Compute Shaders:")
        console.log($1))`$1`frame_processing_time_ms', 0):.2f} ms")
        console.log($1))`$1`temporal_fusion_time_ms', 0):.2f} ms")
        console.log($1))`$1`memory_reduction_percent', 0):.2f}%")
        console.log($1))`$1`estimated_speedup', 1.0):.2f}x\n")
      
      # Print compute shader configuration
        compute_config: any = with_result.get())"compute_shader_config", {})
      if ($1) {
        console.log($1))"Compute Shader Configuration:")
        for key, value in Object.entries($1)):
          if ($1) { ${$1} else {
            console.log($1))`$1`)
    
          }
              return 0

      };
if ($1) {;
  sys.exit())main());